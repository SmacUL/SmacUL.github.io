# 新闻数据爬虫

## 谈谈历史

这个玩意一开始是新闻推荐系统的一部分, 用来爬取今日头条的文章信息. 从它出生到现在, 已经经历过很多次的改版, 需求也发生了比较大的变化. 一开始我认为这个爬虫只要获取新闻数据及文章作者的相关数据就可以了, 但是后期仔细地看一了下数据, 既然是做推荐, 怎么能少了新闻的受众, 也就是普通用户的行为. 于是我打算重写一遍这个爬虫 (不过让我意外的是, 这个 "一遍" 其实是很多遍), 可以说这个爬虫的编写史就是我的 Python 学习史或者说我对推荐系统的认识过程. 

## 总览

在个人水平的限制下, 我所知的爬取数据的手段有两种: 
- 一是直接在渲染好的页面的 DOM 树下获取, 这个速度比较慢, 可以使用 [Selenium](https://selenium.dev/documentation/zh-cn/) 这类工具来完成
- 另一种是组装请求头, 假装浏览器发送请求获取数据. 

那么, 我们的这个爬虫需要的数据包括 文章, 文章的作者, 评论, 评论的作者, 回复, 回复的作者. 至于为什么不把其他的用户拉进来, 因为今日头条的用户数量过于庞大, 而且相互关联, 形成网状, 全部拉下来是不可能的. 而且相比于数据的数量, 我认为更重要的是数据的完整性和纯洁性. 这些数据被爬取下来后将被存储在一个 MySql 数据库中. 

考虑到时间成本, 只对文章内容采用在 DOM 树下爬取的方式 (文章内容没法使用请求, 其实是可以的, 但是得益于头条的反扒机制, 这种方式是不稳定的), 其他都使用伪装请求的方式. 

[一个 GitHub 上对今日头条接口分析的资料](https://github.com/iMeiji/Toutiao/wiki/%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1Api%E5%88%86%E6%9E%90#%E8%8E%B7%E5%8F%96%E6%96%B0%E9%97%BB%E8%AF%84%E8%AE%BA)
