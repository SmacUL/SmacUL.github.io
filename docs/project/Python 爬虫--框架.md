# Python 爬虫--框架

## 谈谈历史

这个玩意, 我现在姑且称为项目吧, 一开始是新闻推荐系统的一部分, 用来爬取今日头条的文章信息. 从它出生到现在, 已经经历过很多次的改版, 从单纯的面向过程再到面向对象, 然后又将爬虫系统中一些重要的配置信息写出 py 文件, 转到 json 文件避免修改代码. 无论怎么操作, 在 Python 随意的语法和 PyCharm 无奈的高亮下, 整个系统的代码看起来还是像一锅意大利面, 每次出 Bug 或是添加功能总是非常折磨人; 

直到有一天, 我突然想起了系统中的 json 配置文件和一个几乎毫无瓜葛的 [Spring](https://spring.io/projects/spring-framework) 框架, 为什么不能模仿 Spring , 实现一个简单的对象容器? 将对象的配置尽可能地暴露在 json 或是 xml 文件中? 提一下 Spring . 这个东西我不算很了解, 但是核心的技术主要是 Ioc 和 AOP , 基础就是对象容器, 当然一切的一切得益于 Java 为所欲为的反射特性; 

那么这个 "项目" , 我就想试一试能不能用借助 Spring 的这些特点来帮助完成一些事情--今日头条的数据爬取; 

## 具体需求

### 数据配置
关于数据配置, 使用 JSON 还是 XML , 我觉得还是 XML 吧, JSON 有些随意, 不方便规范操作; 另外要不要遵循 "约定大于配置" 的原则, 我不太清除, 我想先写一部分感受一下, 反正是一个拓展脑洞的东. 

### 获取数据
我们要获取的主要是 [今日头条](https://www.toutiao.com) 中的新闻数据, 入口就是首页的缩略文章信息, 分析完这一部分之后, 我们可以获得每一篇文章的 url , 再次访问这个 url , 获得文章的具体数据. 总而言之, 在获得每篇文章应有的数据之前, 我们需要访问两个不同的 url .

获取数据的任务交给 [Selenium](https://selenium.dev/documentation/zh-cn/) 包来完成. 

### 分析数据
对于获取到的每一个数据项 (可能是标题, 可能是文章的具体内容), 我们要在获取数据项的前后留出操作空间 (听起来是不是很像 AOP ) , 允许插入处理对象; 

### 保存数据
持久化保存数据有两个方向, 一个是简单的数据文件形式, 另一个就是数据库, 我打算两个都有

### 异常处理
在过去的项目中, 异常处理总是一个被忽视的地方; 这个地方, 我想模仿总多框架的操作, 区分生产和开发模式, 前者在运行过程中会生成数据获取的情况报告, 而后者会在前者的基础上提供更加深层次的异常信息与提示, 方便排除 bug . 

因为今日头条的数据在多次访问之后就会获得大量的重复数据, 在转到生产模式之后, 系统应该允许用户当重复数据达到某一程度时停下, 毕竟时间和计算资源都很有限. 

## 新系统的展望

首先一批基础的处理类会被实现, 它们将负责文件的读写, 数据库的连接, 数据库的读写, 对象与对象的关系协调 (反射 反向注入? 也许吧)

在系统核心类之外, 将会有一批具体的应用类被实现, 它们将会完成高级的数据处理工作. 

另外一个重要任务就是 配置文件 , 它们将为系统注入灵魂, 控制整个系统, 将配置项暴露给用户; 



